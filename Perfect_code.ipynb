{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "import tensorflow as tf\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = TFGPT2LMHeadModel.from_pretrained('gpt2',use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = tokenizer.encode(\"who is a member of the National Security Council,and is a member of\",return_tensors = 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'concrete_function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8c894665bcc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcrete_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'concrete_function' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list()\n",
    "for i in [\"She was really good girl\",\"She was really good girl\",\"She was really good girl\"]:\n",
    "    ids = tokenizer.encode(i,return_tensors = 'tf')\n",
    "    x.append(ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3347,  373, 1107,  922, 2576],\n",
       "       [3347,  373, 1107,  922, 2576],\n",
       "       [3347,  373, 1107,  922, 2576]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'concrete_function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c9be094717b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# import numpy as np\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcrete_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'concrete_function' is not defined"
     ]
    }
   ],
   "source": [
    "# import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "callable = tf.function(model.call)\n",
    "concrete_function = callable.get_concrete_function(tf.TensorSpec([None,None], tf.int32, name=\"input_ids\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = concrete_function(np.array(x))[0][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([np.argmax(concrete_function(np.array(x))[0][0][-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def Top_k(logits,temperature=0.9,k=50):\n",
    "    logits = tf.divide(logits,temperature)\n",
    "#    Take top 50 and then divide the logits by its temperature so we can make low probalabe values even more probabale and less probable values even less probable\n",
    "    values,_=tf.math.top_k(logits, k=50, sorted=True,name = \"top50\") #selecting Top 50 logits\n",
    "#     select the minimum value from each axis and divide with temperature\n",
    "    minimum_values = values[:,-1][:,tf.newaxis]\n",
    "#     Now make all the values below this -1e*10 in the logits this happens by broadcasting \n",
    "    return tf.where(logits<minimum_values,tf.ones_like(logits, dtype=logits.dtype) * -1e10,logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def Top_p(logits, p=0.95):\n",
    "    \"\"\"Nucleus sampling\"\"\"\n",
    "    batch = 3\n",
    "    sorted_logits = tf.sort(logits, direction='DESCENDING', axis=-1)\n",
    "    cumulative_probs = tf.cumsum(tf.nn.softmax(sorted_logits, axis=-1), axis=-1)\n",
    "    indices = tf.stack([\n",
    "        tf.range(0, batch),\n",
    "        # number of indices to include\n",
    "        tf.maximum(tf.reduce_sum(tf.cast(cumulative_probs <= p, tf.int32), axis=-1) - 1, 0),\n",
    "    ], axis=-1)\n",
    "    min_values = tf.gather_nd(sorted_logits, indices)[:,tf.newaxis]\n",
    "    return tf.where(\n",
    "        logits < min_values,\n",
    "        tf.ones_like(logits) * -1e10,\n",
    "        logits,\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_output(input_ids,len,top_k,top_p,temp):\n",
    "    tokens = input_ids\n",
    "    for _ in tf.range(len):\n",
    "        outputs = tf.random.categorical(Top_p(Top_k(concrete_function(tokens)[0][:,-1],temp,top_k),temp),num_samples = 1)\n",
    "        tokens = tf.concat([tokens,tf.cast(outputs,dtype = tf.int32)],1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = get_output.get_concrete_function(tf.TensorSpec([None,None], tf.int32, name=\"input_ids\"),tf.TensorSpec((),tf.int32,name = \"len\"),tf.TensorSpec((),tf.int32,name=\"top_k\"),tf.TensorSpec((),tf.float32,name=\"top_p\"),tf.TensorSpec((),tf.float32,name=\"temp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 15), dtype=int32, numpy=\n",
       "array([[ 1858,  5615,   257,  1468, 16365,   290,   257,  1862,  1200,\n",
       "           11,   351,   262,  2802,   338,  1735],\n",
       "       [ 1858,  5615,   257,  1468, 16365,   290,   257,  1862, 16365,\n",
       "           13,  1119,   550,   262,   976,  2156],\n",
       "       [ 1858,  5615,   257,  1468, 16365,   319,   428,  8598,    11,\n",
       "          290,   340,   373,   845,  1468,    13]])>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function(np.array(x),tf.constant(10),tf.constant(40),tf.constant(.95),tf.constant(.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Top_sentences_2\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model,'Top_sentences_2',signatures = function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = tf.saved_model.load('Top_sentences_2/001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 15), dtype=int32, numpy=\n",
       "array([[ 1858,  5615,   257,  1468, 16365,   508,   373,   262, 16365,\n",
       "          286,   262,  1755,   290,   508,   973],\n",
       "       [ 1858,  5615,   257,  1468, 16365,   290,   257,   922,  1862,\n",
       "          582,    13,   383,  1468, 16365,   290],\n",
       "       [ 1858,  5615,   257,  1468, 16365,    11,   508,  1718,   262,\n",
       "         1438,   286,   705,   464,  7542,  4458]])>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.signatures['serving_default'](input_ids = tf.constant(np.array(x)),len=tf.constant(10),top_p=tf.constant(.9),top_k =tf.constant(40),temp = tf.constant(.9))['output_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list()\n",
    "for i in [\"There lived a old witch\",\"There lived a old witch\",\"There lived a old witch\"]:\n",
    "    ids = tokenizer.encode(i,return_tensors = 'tf')\n",
    "    x.append(ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tf.constant(np.array(x),dtype = tf.int32)\n",
    "for i in range(10):\n",
    "    outputs = tf.random.categorical(Top_p(Top_k(concrete_function(tokens)[0][:,-1]),0.95),num_samples = 1)\n",
    "    tokens = tf.concat([tokens,tf.cast(outputs,dtype = tf.int32)],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There lived a old witch and a man named Ralhaut who were\n",
      "There lived a old witch and a young young man. The story of the\n",
      "There lived a old witch, a woman of great intelligence and good taste,\n"
     ]
    }
   ],
   "source": [
    "for i in tokens:    \n",
    "    print(tokenizer.decode(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "callable = tf.function(model.call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_function = callable.get_concrete_function(tf.TensorSpec([None,None], tf.int32, name=\"input_ids\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_output(np.array(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = get_output.get_concrete_function(tf.TensorSpec([None], tf.int32, name=\"input_ids\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = function(np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There lived a old witch who lived in a castle, and a man of\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There lived a old witch, who died of her illness. And what the'"
      ]
     },
     "execution_count": 890,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Top_sentences_1\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model,'Top_sentences_1',signatures = function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = tf.saved_model.load('Top_sentences_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=model_.signatures['serving_default'](input_ids=tf.constant(np.array(x)))['output_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There lived a old witch with her husband who used to tell her about her\n",
      "There lived a old witch that lived in the house of the witches and the\n",
      "There lived a old witch and her husband who would be executed for witchcraft.\n"
     ]
    }
   ],
   "source": [
    "for i in words:\n",
    "    print(tokenizer.decode(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "server_url = \"http://localhost:8501/v1/models/TypeAhead:predict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_json = json.dumps({\"instances\":[{\"len\":5,\"temp\":0.9,\"input_ids\":np.array(x).tolist(),\"top_k\":40,\"top_p\":0.95}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"instances\": [{\"len\": 5, \"temp\": 0.9, \"input_ids\": [[1858, 5615, 257, 1468, 16365], [1858, 5615, 257, 1468, 16365], [1858, 5615, 257, 1468, 16365]], \"top_k\": 40, \"top_p\": 0.95}]}'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(server_url,data = input_data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"error\": \"The second input must be a scalar, but it has shape [1]\\\\n\\\\t [[{{node while}}]]\"\\n}'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'as_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-e3e814f8dcd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'as_list'"
     ]
    }
   ],
   "source": [
    "tf.constant(5).as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'predictions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-916-a76d1804a052>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'predictions'"
     ]
    }
   ],
   "source": [
    "for i in np.array(response.json()['predictions']):\n",
    "    print(tokenizer.decode(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list()\n",
    "for i in [\"Once upon a time there lived a king without fear whatsoever\",\"Once upon a time there lived a king without fear whatsoever\",\"Once upon a time there lived a king without fear whatsoever\"]:\n",
    "    ids = tokenizer.encode(i,return_tensors = 'tf')\n",
    "    x.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 7454,  2402,   257,   640,   612,  5615,   257,  5822,  1231,\n",
       "          3252, 16014]],\n",
       "\n",
       "       [[ 7454,  2402,   257,   640,   612,  5615,   257,  5822,  1231,\n",
       "          3252, 16014]],\n",
       "\n",
       "       [[ 7454,  2402,   257,   640,   612,  5615,   257,  5822,  1231,\n",
       "          3252, 16014]]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50257,), dtype=float32, numpy=\n",
       "array([-74.626976, -75.38203 , -82.51564 , ..., -87.272064, -83.40596 ,\n",
       "       -77.62991 ], dtype=float32)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function(np.array(x))[0][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 11, 50257), dtype=float32, numpy=\n",
       " array([[[ -34.564377,  -34.408035,  -38.307804, ...,  -41.699547,\n",
       "           -39.78006 ,  -35.05196 ],\n",
       "         [ -84.725494,  -82.93255 ,  -87.01647 , ...,  -91.66669 ,\n",
       "           -86.23538 ,  -84.70934 ],\n",
       "         [-109.07983 , -105.72582 , -109.91147 , ..., -114.284645,\n",
       "          -107.693275, -105.36123 ],\n",
       "         ...,\n",
       "         [ -91.777664,  -92.0373  ,  -97.055466, ...,  -95.54817 ,\n",
       "           -95.6129  ,  -94.27099 ],\n",
       "         [ -66.723076,  -67.995895,  -74.756294, ...,  -77.81113 ,\n",
       "           -75.29102 ,  -70.35248 ],\n",
       "         [ -74.62697 ,  -75.38202 ,  -82.51563 , ...,  -87.27206 ,\n",
       "           -83.405945,  -77.629906]]], dtype=float32)>,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.array(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([np.argmax(model_.signatures['serving_default'](ids[0])['output_0'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "',. of; and for in:.\" that to who\\n but—,\"... as the about at ; from or (!… on [ — which-- against.... among except. because upon - a before with\" -- – when over? save'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(model_.signatures['serving_default'](ids[0])['output_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8558431>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(tf.math.top_k(model(ids)[0][0][-1], k=50, sorted=True,name = \"top50\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50257,), dtype=float32, numpy=\n",
       "array([3.9849447e-06, 3.8622125e-04, 3.7329280e-06, ..., 5.2050410e-08,\n",
       "       1.8702770e-09, 1.6319476e-05], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
