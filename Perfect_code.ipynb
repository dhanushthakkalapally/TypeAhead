{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "import tensorflow as tf\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = TFGPT2LMHeadModel.from_pretrained('gpt2',use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = tokenizer.encode(\"who is a member of the National Security Council,and is a member of\",return_tensors = 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "tokenizer.decode([np.argmax(concrete_function(np.array(x))[0][0][-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list()\n",
    "for i in [\"She was really good girl\",\"She was really good girl\",\"She was really good girl\"]:\n",
    "    ids = tokenizer.encode(i,return_tensors = 'tf')\n",
    "    x.append(ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3347,  373, 1107,  922, 2576],\n",
       "       [3347,  373, 1107,  922, 2576],\n",
       "       [3347,  373, 1107,  922, 2576]])"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np \n",
    "logits = concrete_function(np.array(x))[0][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def Top_k(logits,temperature=0.9,k=50):\n",
    "    logits = tf.divide(logits,temperature)\n",
    "#    Take top 50 and then divide the logits by its temperature so we can make low probalabe values even more probabale and less probable values even less probable\n",
    "    values,_=tf.math.top_k(logits, k=50, sorted=True,name = \"top50\") #selecting Top 50 logits\n",
    "#     select the minimum value from each axis and divide with temperature\n",
    "    minimum_values = values[:,-1][:,tf.newaxis]\n",
    "#     Now make all the values below this -1e*10 in the logits this happens by broadcasting \n",
    "    return tf.where(logits<minimum_values,tf.ones_like(logits, dtype=logits.dtype) * -1e10,logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def Top_p(logits, p=0.95):\n",
    "    \"\"\"Nucleus sampling\"\"\"\n",
    "    batch = 3\n",
    "    sorted_logits = tf.sort(logits, direction='DESCENDING', axis=-1)\n",
    "    cumulative_probs = tf.cumsum(tf.nn.softmax(sorted_logits, axis=-1), axis=-1)\n",
    "    indices = tf.stack([\n",
    "        tf.range(0, batch),\n",
    "        # number of indices to include\n",
    "        tf.maximum(tf.reduce_sum(tf.cast(cumulative_probs <= p, tf.int32), axis=-1) - 1, 0),\n",
    "    ], axis=-1)\n",
    "    min_values = tf.gather_nd(sorted_logits, indices)[:,tf.newaxis]\n",
    "    return tf.where(\n",
    "        logits < min_values,\n",
    "        tf.ones_like(logits) * -1e10,\n",
    "        logits,\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_output(input_ids,len=10,top_k=50,top_p =.95,temp=.9):\n",
    "    for i in tf.range(2):\n",
    "        tf.concat(input_ids,input_ids,0)\n",
    "    tokens = input_ids\n",
    "    print(tokens)\n",
    "    for _ in tf.range(len):\n",
    "        outputs = tf.random.categorical(Top_p(Top_k(concrete_function(tokens)[0][:,-1],temp,top_k),temp),num_samples = 1)\n",
    "        tokens = tf.concat([tokens,tf.cast(outputs,dtype = tf.int32)],1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-06bacf6eaa3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"There lived a old witch\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"There lived a old witch\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"There lived a old witch\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'tf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "x = list()\n",
    "for i in [\"There lived a old witch\",\"There lived a old witch\",\"There lived a old witch\"]:\n",
    "    ids = tokenizer.encode(i,return_tensors = 'tf')\n",
    "    x.append(ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tf.constant(np.array(x),dtype = tf.int32)\n",
    "for i in range(10):\n",
    "    outputs = tf.random.categorical(Top_p(Top_k(concrete_function(tokens)[0][:,-1]),0.95),num_samples = 1)\n",
    "    tokens = tf.concat([tokens,tf.cast(outputs,dtype = tf.int32)],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There lived a old witch and a man named Ralhaut who were\n",
      "There lived a old witch and a young young man. The story of the\n",
      "There lived a old witch, a woman of great intelligence and good taste,\n"
     ]
    }
   ],
   "source": [
    "for i in tokens:    \n",
    "    print(tokenizer.decode(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "callable = tf.function(model.call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_function = callable.get_concrete_function(tf.TensorSpec([None,None], tf.int32, name=\"input_ids\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_output(np.array(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = get_output.get_concrete_function(tf.TensorSpec([None], tf.int32, name=\"input_ids\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = function(np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There lived a old witch who lived in a castle, and a man of\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There lived a old witch, who died of her illness. And what the'"
      ]
     },
     "execution_count": 890,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Top_sentences_1\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model,'Top_sentences_1',signatures = function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = tf.saved_model.load('Top_sentences_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=model_.signatures['serving_default'](input_ids=tf.constant(np.array(x)))['output_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There lived a old witch with her husband who used to tell her about her\n",
      "There lived a old witch that lived in the house of the witches and the\n",
      "There lived a old witch and her husband who would be executed for witchcraft.\n"
     ]
    }
   ],
   "source": [
    "for i in words:\n",
    "    print(tokenizer.decode(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "server_url = \"http://localhost:8501/v1/models/TypeAhead:predict\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-695cce32dc71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_json = json.dumps({\"signature_name\":\"serving_default\",\"instances\":[10,20,30]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"signature_name\": \"serving_default\", \"instances\": [10, 20, 30]}'"
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(server_url,data = input_data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'predictions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-916-a76d1804a052>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'predictions'"
     ]
    }
   ],
   "source": [
    "for i in np.array(response.json()['predictions']):\n",
    "    print(tokenizer.decode(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list()\n",
    "for i in [\"Once upon a time there lived a king without fear whatsoever\",\"Once upon a time there lived a king without fear whatsoever\",\"Once upon a time there lived a king without fear whatsoever\"]:\n",
    "    ids = tokenizer.encode(i,return_tensors = 'tf')\n",
    "    x.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 7454,  2402,   257,   640,   612,  5615,   257,  5822,  1231,\n",
       "          3252, 16014]],\n",
       "\n",
       "       [[ 7454,  2402,   257,   640,   612,  5615,   257,  5822,  1231,\n",
       "          3252, 16014]],\n",
       "\n",
       "       [[ 7454,  2402,   257,   640,   612,  5615,   257,  5822,  1231,\n",
       "          3252, 16014]]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50257,), dtype=float32, numpy=\n",
       "array([-74.626976, -75.38203 , -82.51564 , ..., -87.272064, -83.40596 ,\n",
       "       -77.62991 ], dtype=float32)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function(np.array(x))[0][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 11, 50257), dtype=float32, numpy=\n",
       " array([[[ -34.564377,  -34.408035,  -38.307804, ...,  -41.699547,\n",
       "           -39.78006 ,  -35.05196 ],\n",
       "         [ -84.725494,  -82.93255 ,  -87.01647 , ...,  -91.66669 ,\n",
       "           -86.23538 ,  -84.70934 ],\n",
       "         [-109.07983 , -105.72582 , -109.91147 , ..., -114.284645,\n",
       "          -107.693275, -105.36123 ],\n",
       "         ...,\n",
       "         [ -91.777664,  -92.0373  ,  -97.055466, ...,  -95.54817 ,\n",
       "           -95.6129  ,  -94.27099 ],\n",
       "         [ -66.723076,  -67.995895,  -74.756294, ...,  -77.81113 ,\n",
       "           -75.29102 ,  -70.35248 ],\n",
       "         [ -74.62697 ,  -75.38202 ,  -82.51563 , ...,  -87.27206 ,\n",
       "           -83.405945,  -77.629906]]], dtype=float32)>,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.array(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([np.argmax(model_.signatures['serving_default'](ids[0])['output_0'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "',. of; and for in:.\" that to who\\n but—,\"... as the about at ; from or (!… on [ — which-- against.... among except. because upon - a before with\" -- – when over? save'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(model_.signatures['serving_default'](ids[0])['output_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8558431>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(tf.math.top_k(model(ids)[0][0][-1], k=50, sorted=True,name = \"top50\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50257,), dtype=float32, numpy=\n",
       "array([3.9849447e-06, 3.8622125e-04, 3.7329280e-06, ..., 5.2050410e-08,\n",
       "       1.8702770e-09, 1.6319476e-05], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
